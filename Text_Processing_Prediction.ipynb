{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Processing for Similarity and Sentence Relationship Prediction**"
      ],
      "metadata": {
        "id": "17D_QLfBaKaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task Review**\n",
        "\n",
        "The goal of this project is to develop a deep learning model that determines whether a given sentence can be used as part of an answer to a specific question. We use a dataset (`train.csv`) that contains:\n",
        "\n",
        "- **qtext**: The question text.\n",
        "- **atext**: The answer text.\n",
        "- **label**: A binary indicator (1 if the answer is relevant to the question, 0 otherwise).\n",
        "\n",
        "To achieve this, we implement a **Siamese Neural Network** using **TensorFlow-Keras** and perform two tasks:\n",
        "\n",
        "1. **Task 1: Simple Siamese Neural Network with Contrastive Loss**  \n",
        "   We build a Siamese network that learns embeddings of questions and answers, then applies contrastive loss to measure similarity.\n",
        "\n",
        "2. **Task 2: Transformer-Based Model for Sentence Relationship Prediction**    \n",
        "   We use a Transformer model (such as BERT) to determine whether a given question and answer pair are related.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RHoht4-eaQOx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTer8XWk7xaR"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The data is in the file `train.csv`, which is provided in GitHub repository. Each row of the file consists of a question ('qtext' column), an answer ('atext' column), and a label ('label' column) that indicates whether the  answer is correctly related to the question (1) or not (0).\n",
        "\n",
        "The following code uses pandas to store the file `train.csv` in a data frame and shows the first few rows of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HyULJPB7xaS",
        "outputId": "5106ef21-533a-4eeb-9bbe-774c0b35d11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            qtext  label  \\\n",
              "0             What are the symptoms of gastritis?      1   \n",
              "1             What are the symptoms of gastritis?      0   \n",
              "2             What are the symptoms of gastritis?      0   \n",
              "3  What does the treatment for gastritis involve?      1   \n",
              "4  What does the treatment for gastritis involve?      1   \n",
              "\n",
              "                                               atext  \n",
              "0  However, the most common symptoms include: Nau...  \n",
              "1  var s_context; s_context= s_context || {}; s_c...  \n",
              "2  !s_sensitive, chron ID: $('article embeded_mod...  \n",
              "3  Treatment for gastritis usually involves: Taki...  \n",
              "4  Eliminating irritating foods from your diet su...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb845415-41b2-4533-925b-5cc115ad08c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qtext</th>\n",
              "      <th>label</th>\n",
              "      <th>atext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the symptoms of gastritis?</td>\n",
              "      <td>1</td>\n",
              "      <td>However, the most common symptoms include: Nau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the symptoms of gastritis?</td>\n",
              "      <td>0</td>\n",
              "      <td>var s_context; s_context= s_context || {}; s_c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the symptoms of gastritis?</td>\n",
              "      <td>0</td>\n",
              "      <td>!s_sensitive, chron ID: $('article embeded_mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does the treatment for gastritis involve?</td>\n",
              "      <td>1</td>\n",
              "      <td>Treatment for gastritis usually involves: Taki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What does the treatment for gastritis involve?</td>\n",
              "      <td>1</td>\n",
              "      <td>Eliminating irritating foods from your diet su...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb845415-41b2-4533-925b-5cc115ad08c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb845415-41b2-4533-925b-5cc115ad08c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb845415-41b2-4533-925b-5cc115ad08c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84c48719-293f-4494-8041-b3c5583fec8c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84c48719-293f-4494-8041-b3c5583fec8c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84c48719-293f-4494-8041-b3c5583fec8c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 9380,\n  \"fields\": [\n    {\n      \"column\": \"qtext\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1998,\n        \"samples\": [\n          \"What should you do if you think you have photophobia?\",\n          \"What are signs of hypomania in bipolar II disorder?\",\n          \"What should I do if I have diabetes and have minor foot problems like bunions, hammertoe, plantar warts, or athlete's foot?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atext\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4530,\n        \"samples\": [\n          \"But higher levels can come from other autoimmune diseases, an infection, a tumor, liver disease, or pregnancy, too.\",\n          \"Guillain- Barre syndrome strikes quickly.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"train.csv\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTTgRnN0dC4"
      },
      "source": [
        "# Task 1: Simple Siamese NN - Contrastive Loss\n",
        "\n",
        "In this task, we implement a **basic Siamese neural network** to determine the similarity between a question and an answer. The model takes in pairs of question-answer embeddings and learns to minimize the distance between related pairs while maximizing the distance between unrelated pairs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Assets for Task 1"
      ],
      "metadata": {
        "id": "vFuL75V3N_y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY6sDbUn0dC6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading and Preprocessing Data"
      ],
      "metadata": {
        "id": "nQLK-DTpOMiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is loaded, and questions, answers, and labels are selected. Next, the dataset is split, with 80% allocated for training and 20% reserved for validation, which will be used to evaluate the model's performance during training. TF-IDF is applied to convert the text into numerical form, facilitating processing by the model. Lastly, all elements are reshaped appropriately for input into TensorFlow."
      ],
      "metadata": {
        "id": "61x3X6LgGKeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting questions, answers, and labels from the dataset\n",
        "questions = dataset['qtext'].values\n",
        "answers = dataset['atext'].values\n",
        "labels = dataset['label'].values\n",
        "\n",
        "# Splitting data into training and validation sets (80% train, 20% validation)\n",
        "q_train, q_val, a_train, a_val, y_train, y_val = train_test_split(questions, answers, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorizer for both question and answer text\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limit vocab size to 5000 to keep things efficient\n",
        "\n",
        "# Fitting the TF-IDF on both the question and answer text, then transform\n",
        "q_train_tfidf = tfidf_vectorizer.fit_transform(q_train)\n",
        "a_train_tfidf = tfidf_vectorizer.transform(a_train)\n",
        "q_val_tfidf = tfidf_vectorizer.transform(q_val)\n",
        "a_val_tfidf = tfidf_vectorizer.transform(a_val)\n",
        "\n",
        "# Converting the sparse matrices to dense arrays so TensorFlow can work with them\n",
        "q_train_tfidf = q_train_tfidf.toarray()\n",
        "a_train_tfidf = a_train_tfidf.toarray()\n",
        "q_val_tfidf = q_val_tfidf.toarray()\n",
        "a_val_tfidf = a_val_tfidf.toarray()\n",
        "\n",
        "# Checking that everything loaded correctly\n",
        "print(\"Shapes of the transformed data:\", q_train_tfidf.shape, a_train_tfidf.shape, q_val_tfidf.shape, a_val_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwF2s7XAOUo6",
        "outputId": "a98b7ee2-fdb5-4a14-fb2b-7454bb607c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the transformed data: (7504, 1878) (7504, 1878) (1876, 1878) (1876, 1878)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 7,504 pairs designated for training and 1,876 pairs for validation, each consisting of 1,878 features derived from TF-IDF. Both questions and answers share the same number of features, ensuring consistency before feeding them into the model. This confirms that preprocessing was successful, paving the way for the next step: building the neural network."
      ],
      "metadata": {
        "id": "z-PzVINkG9zo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building the Siamese Neural Network Model"
      ],
      "metadata": {
        "id": "VdKKkbkWJHGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to construct a Siamese Network, incorporating a pair of input layers, one for questions and one for answers. These inputs pass through two shared layers with ReLU activations, set to a size of 128, though this parameter can be adjusted. The Euclidean distance between the question and answer is then calculated to determine their similarity. Finally, a Sigmoid layer at the end outputs the probability that the question and answer pair matches."
      ],
      "metadata": {
        "id": "5u7v6j4oJPdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Siamese model architecture\n",
        "def siamese_model(input_shape, hidden_size):\n",
        "    # Defining input layers for the question and answer pairs with correct shape tuple\n",
        "    input_q = layers.Input(shape=(input_shape,))\n",
        "    input_a = layers.Input(shape=(input_shape,))\n",
        "\n",
        "    # Creating shared hidden layers with ReLU activation\n",
        "    shared_layer_1 = layers.Dense(hidden_size, activation='relu')\n",
        "    shared_layer_2 = layers.Dense(hidden_size, activation='relu')\n",
        "\n",
        "    # Processing question and answer through shared layers\n",
        "    processed_q = shared_layer_2(shared_layer_1(input_q))\n",
        "    processed_a = shared_layer_2(shared_layer_1(input_a))\n",
        "\n",
        "    # Calculating the Euclidean distance between the two processed outputs\n",
        "    distance = layers.Lambda(lambda tensors: tf.norm(tensors[0] - tensors[1], axis=1, keepdims=True))([processed_q, processed_a])\n",
        "\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    output = layers.Dense(1, activation='sigmoid')(distance)\n",
        "\n",
        "    # Defining the full model\n",
        "    model = Model(inputs=[input_q, input_a], outputs=output)\n",
        "\n",
        "    # Compiling the model using binary crossentropy and Adam optimizer\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set hidden layer size and input shape correctly as a single value (int) in a tuple\n",
        "hidden_size = 128\n",
        "input_shape = q_train_tfidf.shape[1]  # Feature size\n",
        "model = siamese_model(input_shape, hidden_size)\n",
        "\n",
        "# Displaying the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "CF4WdmTJLaZw",
        "outputId": "2788a213-b42f-4b52-e96b-c235519fc931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1878\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1878\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m240,512\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m16,512\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dense_6[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dense_7[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m2\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1878</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1878</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240,512</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m257,026\u001b[0m (1004.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">257,026</span> (1004.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m257,026\u001b[0m (1004.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">257,026</span> (1004.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model consists of two input layers each receiving TF-IDF vectors with 1,878 features. These inputs are processed through two shared dense layers with 128 units and ReLU activation. Following this, a Lambda layer calculates the Euclidean distance between the question and answer embeddings. Finally, a Sigmoid output layer predicts whether the answer matches the question. The model comprises a total of 257,026 parameters, all of which are trainable."
      ],
      "metadata": {
        "id": "mo6MCrtpNAo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training the Model"
      ],
      "metadata": {
        "id": "pQBXld9cOBsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, the model is trained by feeding it both the training and validation data, running for 10 epochs. During training, it calculates the binary cross-entropy loss, adjusts weights accordingly, and evaluates performance using the validation data to monitor progress."
      ],
      "metadata": {
        "id": "fLECRrHnOMje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model with the training data\n",
        "history = model.fit([q_train_tfidf, a_train_tfidf], y_train,\n",
        "                    validation_data=([q_val_tfidf, a_val_tfidf], y_val),\n",
        "                    epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyAM49n3Oewi",
        "outputId": "68e9b9cc-6cc5-41d7-a4e1-ab15554d52c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5089 - loss: 0.6911 - val_accuracy: 0.7074 - val_loss: 0.6373\n",
            "Epoch 2/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.5794 - val_accuracy: 0.7799 - val_loss: 0.5695\n",
            "Epoch 3/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8599 - loss: 0.4653 - val_accuracy: 0.8124 - val_loss: 0.5349\n",
            "Epoch 4/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.3787 - val_accuracy: 0.8166 - val_loss: 0.5194\n",
            "Epoch 5/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.3125 - val_accuracy: 0.8140 - val_loss: 0.5114\n",
            "Epoch 6/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.2694 - val_accuracy: 0.8332 - val_loss: 0.5175\n",
            "Epoch 7/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9338 - loss: 0.2453 - val_accuracy: 0.8364 - val_loss: 0.5103\n",
            "Epoch 8/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.2091 - val_accuracy: 0.8401 - val_loss: 0.5042\n",
            "Epoch 9/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.2021 - val_accuracy: 0.8326 - val_loss: 0.5225\n",
            "Epoch 10/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1833 - val_accuracy: 0.8364 - val_loss: 0.5157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model trained over 10 epochs, showing a steady improvement in both accuracy and validation accuracy with each epoch. Starting at approximately 50.9% accuracy, the model quickly identified patterns, reaching 95.0% accuracy on the training set by the final epoch. Validation accuracy also improved, ending around 83.6%. Both training and validation loss values consistently decreased, indicating effective learning without signs of overfitting. This upward trend in accuracy and reduction in loss values suggest that the model is training well, effectively capturing the relationship between questions and answers."
      ],
      "metadata": {
        "id": "RiBQeh4iQmTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Evaluating the Model on Test Data"
      ],
      "metadata": {
        "id": "7Fo7NDczQuMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With training complete, the test data is loaded, providing an unbiased measure of the model's performance on unseen data. After transforming the test text data into TF-IDF vectors, it is fed into the model to obtain the test accuracy, offering a realistic assessment of the model’s effectiveness."
      ],
      "metadata": {
        "id": "cXx1_N4OQ1_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test data\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Preparing the test data\n",
        "q_test = test_df['qtext'].values\n",
        "a_test = test_df['atext'].values\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "# Transforming test data using the same TF-IDF vectorizer\n",
        "q_test_tfidf = tfidf_vectorizer.transform(q_test).toarray()\n",
        "a_test_tfidf = tfidf_vectorizer.transform(a_test).toarray()\n",
        "\n",
        "# Evaluating the model on test data\n",
        "test_loss, test_acc = model.evaluate([q_test_tfidf, a_test_tfidf], y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPCLYR4cQ1hr",
        "outputId": "81a87f72-91d8-4cd8-8a94-05741ef6836e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5492 - loss: 1.2981\n",
            "Test accuracy: 0.5642273426055908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy was approximately 54.9%, with a loss of 1.2981. This result indicates that the model may be struggling to generalize to new data, performing notably less effectively than on the training and validation sets. The disparity between training and test accuracy suggests potential overfitting on the training data or that the TF-IDF features might be insufficient to capture deeper semantic relationships, limiting the model's ability to generalize effectively."
      ],
      "metadata": {
        "id": "kgByoLEESJfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Identifying a Failure Case"
      ],
      "metadata": {
        "id": "2zlmTrb0YNrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, the model is used to make predictions on the test set, and any failure cases where it misclassified answers are examined. By identifying and analyzing these cases, insights are gained into specific areas where the model could be improved."
      ],
      "metadata": {
        "id": "qGB8z6ZYYXMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test set to identify a failure case\n",
        "y_pred = model.predict([q_test_tfidf, a_test_tfidf])\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Finding a failure case where the prediction is incorrect\n",
        "for i in range(len(y_test)):\n",
        "    if y_pred_labels[i] != y_test[i]:\n",
        "        print(f\"Failure case at index {i}:\")\n",
        "        print(f\"Question: {q_test[i]}\")\n",
        "        print(f\"Answer: {a_test[i]}\")\n",
        "        print(f\"True Label: {y_test[i]}, Predicted: {y_pred_labels[i]}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsrOqaQY5BM",
        "outputId": "bc17d921-ec0d-4bc1-98f9-3d08bb197676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Failure case at index 0:\n",
            "Question: How does an external catheter help male incontinence?\n",
            "Answer: External catheters.\n",
            "True Label: 1, Predicted: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this failure case, the model was tasked with determining the relevance of the answer to the question, \"How does an external catheter help male incontinence?\" The answer, \"External catheters,\" is indeed correct (True Label = 1), but the model incorrectly classified it as irrelevant (Predicted = 0). This error likely occurred because TF-IDF struggles to capture the nuanced context and meaning behind the question-answer pair. The model interprets the phrases as collections of isolated words, without recognizing that \"External catheters\" directly addresses the question. To enhance performance, increasing the volume of training data may improve the model's generalization capabilities."
      ],
      "metadata": {
        "id": "R32kVg0IgUwI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l8xrhwf7xaW"
      },
      "source": [
        "# Task 2: Transformer neural network\n",
        "\n",
        "In this task, we replace the Siamese Neural Network with a **Transformer-based model** to determine whether two sentences (a question and an answer) are related. The Transformer reads both the question and answer **simultaneously**, capturing deeper contextual relationships.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Assets for Task 2"
      ],
      "metadata": {
        "id": "HlFg5a0-zRYy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8RRCWeQTrPl"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from tensorflow.keras.layers import Embedding, Layer\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
        "from tensorflow.keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preparation"
      ],
      "metadata": {
        "id": "TxHK2JKCvCNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, qtext and atext are concatenated with a [SEP] token placed between them to create a single input sequence. Next, an appropriate padding length is determined based on the text length distribution, ensuring consistent input sizes across all samples."
      ],
      "metadata": {
        "id": "mgMZnG_SvH-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate question and answer text with [SEP] separator\n",
        "dataset['combined_text'] = dataset['qtext'] + \" [SEP] \" + dataset['atext']\n",
        "\n",
        "# Calculate text lengths to determine padding length\n",
        "dataset['text_length'] = dataset['combined_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Display statistics for text length\n",
        "length_stats = dataset['text_length'].describe()\n",
        "print(\"Text Length Statistics:\", length_stats)"
      ],
      "metadata": {
        "id": "QgmuxfkLvWhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f67a5a-dc24-4849-e117-ee2b8b78a74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Length Statistics: count    9380.000000\n",
            "mean       28.106716\n",
            "std        14.022191\n",
            "min         5.000000\n",
            "25%        20.000000\n",
            "50%        25.000000\n",
            "75%        32.000000\n",
            "max       219.000000\n",
            "Name: text_length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After analyzing the lengths of the concatenated qtext and atext inputs, it was observed that most texts fall within 32 tokens or fewer. To efficiently cover the majority of the data, a padding length of 50 tokens is set. This choice captures most of the data without excessive padding. With this padding length defined, the next step is to tokenize and pad the inputs to this fixed length, ensuring uniform input sizes."
      ],
      "metadata": {
        "id": "pFA397AjvHJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. BERT Tokenizer"
      ],
      "metadata": {
        "id": "bsCmDa5FyfY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to initialize the BERT tokenizer, using it to tokenize and pad each concatenated sentence to a maximum length of 50 tokens. The tokenizer automatically inserts [CLS] and [SEP] tokens, marking the start and separation within each input. Additionally, an attention mask is generated to help the model focus on meaningful tokens while ignoring the padding tokens."
      ],
      "metadata": {
        "id": "_V0cA4CDym2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Setting maximum length based on the analysis\n",
        "max_length = 50\n",
        "\n",
        "# Defining function to tokenize and pad inputs\n",
        "def tokenize_and_pad(sentences, max_length):\n",
        "\n",
        "    tokens = tokenizer(\n",
        "        sentences,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "    return tokens\n",
        "\n",
        "# Applying tokenization to the training data\n",
        "train_sentences = dataset['combined_text'].tolist()\n",
        "train_tokens = tokenize_and_pad(train_sentences, max_length)\n",
        "\n",
        "# Displaying a sample of the tokenized data\n",
        "print(\"Sample input_ids:\", train_tokens['input_ids'][0])\n",
        "print(\"Sample attention_mask:\", train_tokens['attention_mask'][0])"
      ],
      "metadata": {
        "id": "HOu-eW6VvAD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460,
          "referenced_widgets": [
            "3500a1362f294095933ac308dcc25dac",
            "62928734b47a496d97a8ac3d01915204",
            "716bb9bda4d24a6f9f3400b7f8fc5bf1",
            "077b196593854b07a82c663b84335c61",
            "87efc2f4380449dca6b326b4dd2dfcaa",
            "866eb63a8d8b4fd19ead508fb09a748b",
            "1411ca0fb75948d68f190efed9c0e13d",
            "bf1060e137cf4714802941f38a0386ec",
            "f500a459f63c408bad8f9193b68b0a2d",
            "898a66e243cd4ca799c9625f84c08ab3",
            "440b2446857c4113a74b35a77d30212a",
            "a9bb8e60c6484f1fae89b05b82fe790c",
            "0f97d994a60d4834a1dde6dcd89dc85f",
            "3bcd01518a174a1a9ac264a1007cad34",
            "7f4ce309d19f4f91ad6963e343b97d0f",
            "b1d6041d64f640fab876394d6ccf9d31",
            "61a0b9f0ce9a47309026056dec530d00",
            "34bc1d4571cb494f98dac4fa6374b7d6",
            "ce1b6ed8fd654e20afb6cc89f5837d9c",
            "a9776f35b8534806a79932ea027d912a",
            "377e5f5435bc4d2f8292fba27d3f4843",
            "bc2c61e7342e4966b4de5b1654955816",
            "a14020105b57477c9c70c61b88546866",
            "65af1e2a7d714e5b8361dd2cf81b1b3c",
            "b5ced02830c94b5b8e9d67f041e7a473",
            "3b2cf674c28040fd99fdf04150d5042b",
            "4dbbe87fbdb14bc285afb14e13ac656b",
            "15527272405e42c3ad14f79b5e290d2a",
            "60504385c3dc434c934f69229f39c3a8",
            "01e10f1b6c4b46dea081ed27ead1801b",
            "e6bdaa0897144ea795e58e290e97ea0d",
            "ef827a3104164ed0a96e280383095506",
            "629f3231c14245d9acd564e07014d88d",
            "b652d782f8ca41e3af2b977c33d8e366",
            "81c2817e97574e26aa6bd08380ae6b06",
            "4054cb166ee74662bd8313ca8172e57f",
            "985edcdb80d84d35b1f1e03b010ad276",
            "0ed6eebfcb4540059074c71f353361be",
            "69c3be6138834c72978afcee48f41df9",
            "217d1abf2ca04cfa9d00724812ca5542",
            "048c748103d143029f52bea39f45a259",
            "fb380a96e6554339b7da8ab95838d539",
            "f5107f42c19f48d392016c9094580af4",
            "92e02f50739942548ca76e31b9d96ec5"
          ]
        },
        "outputId": "478e1015-56a1-480c-ea00-abd785d8ce54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3500a1362f294095933ac308dcc25dac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9bb8e60c6484f1fae89b05b82fe790c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a14020105b57477c9c70c61b88546866"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b652d782f8ca41e3af2b977c33d8e366"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input_ids: tf.Tensor(\n",
            "[  101  2054  2024  1996  8030  1997  3806 18886  7315  1029   102  2174\n",
            "  1010  1996  2087  2691  8030  2421  1024 19029  2030 28667 29264  6314\n",
            "  4308 21419  1038  4135  5844 21419  3255 24780 27427 25538 16643  2239\n",
            "  5255  2030  1043  2532  9328  3110  1999  1996  4308  2090 12278  2030\n",
            "  2012   102], shape=(50,), dtype=int32)\n",
            "Sample attention_mask: tf.Tensor(\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(50,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The BERT tokenizer successfully tokenized and padded the input to our fixed length of 50 tokens. It added special tokens like [CLS] at the start and [SEP] between the question and answer, which helps the Transformer understand sentence boundaries. The attention mask has 1s for real tokens, helping the model ignore any padded 0s. This prepares our data for embedding and Transformer layers!"
      ],
      "metadata": {
        "id": "gtFLHvyQ1eSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Embedding Layer with Positional Encoding"
      ],
      "metadata": {
        "id": "V8wSN72F2Rp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, an embedding layer is created to convert input tokens into 128-dimensional vectors. To provide the model with a sense of token order, positional encoding is added, enabling the Transformer model to understand the sequence structure, as it lacks inherent awareness of token positions."
      ],
      "metadata": {
        "id": "FpuFe3QL2mla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a positional encoding layer\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "        pos = np.arange(max_len)[:, np.newaxis]\n",
        "        i = np.arange(d_model)[np.newaxis, :]\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "        angle_rads = pos * angle_rates\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        # Ensure positional encoding matches input dtype\n",
        "        self.pos_encoding = tf.constant(angle_rads, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:tf.shape(inputs)[1], :]\n",
        "\n",
        "# Defining embedding layer with positional encoding\n",
        "def embedding_layer(vocab_size, d_model, max_len):\n",
        "    inputs = tf.keras.Input(shape=(max_len,))\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
        "    x = PositionalEncoding(max_len, d_model)(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Setting embedding parameters\n",
        "vocab_size = tokenizer.vocab_size\n",
        "d_model = 128\n",
        "\n",
        "# Initializing embedding layer with positional encoding\n",
        "embedding_model = embedding_layer(vocab_size, d_model, max_length)\n",
        "\n",
        "# Sample input: Using one of the tokenized input_ids from the train_tokens\n",
        "sample_input_ids = train_tokens['input_ids'][:1]  # Taking one example from the batch\n",
        "\n",
        "# Getting the embedding output with positional encoding\n",
        "embedding_output = embedding_model(sample_input_ids)\n",
        "\n",
        "# Printing the embedding output to verify the result\n",
        "print(\"Embedding output with positional encoding (shape):\", embedding_output.shape)\n",
        "print(\"Sample output:\", embedding_output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkGwCt852t68",
        "outputId": "ccaa397a-ab4f-4fe5-f639-044c8c6b7276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding output with positional encoding (shape): (1, 50, 128)\n",
            "Sample output: tf.Tensor(\n",
            "[[ 1.6350523e-03  1.0258011e+00 -3.4834612e-02 ...  9.5547342e-01\n",
            "  -1.1562336e-02  9.5087886e-01]\n",
            " [ 8.3524549e-01  5.4265457e-01  7.1763569e-01 ...  1.0108898e+00\n",
            "   3.4194555e-02  1.0419756e+00]\n",
            " [ 8.7638736e-01 -3.9657301e-01  1.0246983e+00 ...  1.0436763e+00\n",
            "  -7.3983561e-04  1.0081265e+00]\n",
            " ...\n",
            " [ 1.2071256e-01 -1.0252832e+00  1.3299796e-01 ...  9.6860737e-01\n",
            "   4.8615340e-02  9.8436600e-01]\n",
            " [-7.5566745e-01 -6.5389681e-01 -6.6543615e-01 ...  1.0179409e+00\n",
            "  -3.8014587e-02  1.0014055e+00]\n",
            " [-9.1342717e-01  3.3013472e-01 -9.5983255e-01 ...  9.5620090e-01\n",
            "   3.9326649e-02  1.0175080e+00]], shape=(50, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding layer with positional encoding is functioning as expected, converting each input token into a 128-dimensional vector that includes positional information to aid the model in understanding token order. The output shape of (1, 50, 128) verifies that inputs are processed correctly, with each sequence containing 50 tokens and an embedding dimension of 128. With this setup confirmed, the next step is to proceed to the Transformer encoder layer!"
      ],
      "metadata": {
        "id": "uhPXy5eO6IcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Transformer Encoder Layer"
      ],
      "metadata": {
        "id": "UCSdoGOR6QBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Transformer encoder layer is added with a hidden dimension selected from the options {64, 128, 256}. To allow the model to attend to various parts of the input sequence, 3 attention heads are set up in the MultiHeadAttention component. This configuration enables the model to capture different aspects of the input’s contextual information effectively."
      ],
      "metadata": {
        "id": "rLJ9Et5Z6dTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Transformer encoder layer\n",
        "def transformer_encoder_layer(d_model, num_heads):\n",
        "    inputs = tf.keras.Input(shape=(max_length, d_model))\n",
        "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
        "    attention_output = LayerNormalization()(attention_output + inputs)  # Add & Norm\n",
        "    dense_output = Dense(d_model, activation='relu')(attention_output)\n",
        "    dense_output = LayerNormalization()(dense_output + attention_output)  # Add & Norm\n",
        "    return tf.keras.Model(inputs=inputs, outputs=dense_output)\n",
        "\n",
        "# Initializing Transformer encoder\n",
        "encoder_model = transformer_encoder_layer(d_model=128, num_heads=3)"
      ],
      "metadata": {
        "id": "r5wmPJAI7xNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don’t need a **Transformer decoder layer** because we’re not generating sequences. Instead, we’re simply classifying whether two sentences are related, which only requires encoding."
      ],
      "metadata": {
        "id": "Stc5ZIeF9Yt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Classification Layers"
      ],
      "metadata": {
        "id": "IZBcNI_19iPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is to add a hidden layer with 256 units and a final output layer with 2 units for binary classification."
      ],
      "metadata": {
        "id": "sZXXM8ZS-FN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining classification head\n",
        "def classification_head(d_model):\n",
        "    inputs = tf.keras.Input(shape=(max_length, d_model))\n",
        "    x = Flatten()(inputs)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    outputs = Dense(2, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Initializing classification model\n",
        "classification_model = classification_head(d_model=128)"
      ],
      "metadata": {
        "id": "sMZsNtCb-Sae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Loss Function Selection"
      ],
      "metadata": {
        "id": "xjs2LLIA-_30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use sparse categorical crossentropy as our loss function, which is suitable for binary classification with integer labels (0 or 1)."
      ],
      "metadata": {
        "id": "edbASEmj_ET5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "yq1eVP47_IG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model Training and Evaluation"
      ],
      "metadata": {
        "id": "sA3FIhljAKrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the model components prepared, the full model is constructed by combining the embedding layer, Transformer encoder, and a classification head. This integrated setup forms the SentencePairClassifier model, designed to take in tokenized text and output a prediction indicating whether the question and answer are related."
      ],
      "metadata": {
        "id": "cYwcLctyAYTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and prepare the validation set\n",
        "val_df = pd.read_csv(\"val.csv\")\n",
        "\n",
        "# Concatenate question and answer with [SEP] for the validation set\n",
        "val_df['combined_text'] = val_df['qtext'] + \" [SEP] \" + val_df['atext']\n",
        "\n",
        "# Tokenizing and pad the validation data\n",
        "val_sentences = val_df['combined_text'].tolist()\n",
        "val_tokens = tokenize_and_pad(val_sentences, max_length)  # Use the same function and max_length as for training\n",
        "\n",
        "# Assembling the full model\n",
        "class SentencePairClassifier(Model):\n",
        "    def __init__(self, vocab_size, d_model, max_length):\n",
        "        super(SentencePairClassifier, self).__init__()\n",
        "        # Embedding layer with positional encoding\n",
        "        self.embedding = embedding_layer(vocab_size, d_model, max_length)\n",
        "\n",
        "        # Transformer encoder layer to add context with multi-head attention\n",
        "        self.encoder = transformer_encoder_layer(d_model=d_model, num_heads=3)\n",
        "\n",
        "        # Classification head for binary classification\n",
        "        self.classifier = classification_head(d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Forward pass through embedding, encoder, and classification head\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.encoder(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Setting parameters for embedding and model dimensions\n",
        "vocab_size = tokenizer.vocab_size\n",
        "d_model = 128\n",
        "max_length = 50\n",
        "\n",
        "# Initializing the model\n",
        "model = SentencePairClassifier(vocab_size=vocab_size, d_model=d_model, max_length=max_length)\n",
        "\n",
        "# Compiling the model\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()  # Loss function for binary classification\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Setting training parameters\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Training the model using training and validation data\n",
        "history = model.fit(\n",
        "    train_tokens['input_ids'],      # Training input data\n",
        "    dataset['label'],              # Training labels\n",
        "    validation_data=(val_tokens['input_ids'], val_df['label']),  # Validation data\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Loading and prepare the test set (assuming test.csv is available)\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Concatenating question and answer with [SEP] for the test set\n",
        "test_df['combined_text'] = test_df['qtext'] + \" [SEP] \" + test_df['atext']\n",
        "\n",
        "# Tokenizing and pad the test data\n",
        "test_sentences = test_df['combined_text'].tolist()\n",
        "test_tokens = tokenize_and_pad(test_sentences, max_length)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "test_accuracy = model.evaluate(test_tokens['input_ids'], test_df['label'], batch_size=batch_size)\n",
        "print(f\"Test accuracy: {test_accuracy[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyBULYgPBSWm",
        "outputId": "0f5dec93-afa3-4d27-82ab-068bb1d06e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 252ms/step - accuracy: 0.5188 - loss: 1.4506 - val_accuracy: 0.4502 - val_loss: 0.7676\n",
            "Epoch 2/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 180ms/step - accuracy: 0.5260 - loss: 0.7181 - val_accuracy: 0.4676 - val_loss: 1.1145\n",
            "Epoch 3/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 204ms/step - accuracy: 0.6519 - loss: 0.6521 - val_accuracy: 0.6110 - val_loss: 0.7645\n",
            "Epoch 4/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 337ms/step - accuracy: 0.8326 - loss: 0.3826 - val_accuracy: 0.6243 - val_loss: 0.7572\n",
            "Epoch 5/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 194ms/step - accuracy: 0.8904 - loss: 0.2740 - val_accuracy: 0.5253 - val_loss: 1.3806\n",
            "Epoch 6/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 189ms/step - accuracy: 0.9250 - loss: 0.2013 - val_accuracy: 0.5867 - val_loss: 1.0262\n",
            "Epoch 7/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 187ms/step - accuracy: 0.9406 - loss: 0.1513 - val_accuracy: 0.6241 - val_loss: 1.0115\n",
            "Epoch 8/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 186ms/step - accuracy: 0.9458 - loss: 0.1392 - val_accuracy: 0.5518 - val_loss: 1.6844\n",
            "Epoch 9/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 190ms/step - accuracy: 0.9567 - loss: 0.1112 - val_accuracy: 0.5729 - val_loss: 1.9519\n",
            "Epoch 10/10\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 182ms/step - accuracy: 0.9602 - loss: 0.1018 - val_accuracy: 0.5741 - val_loss: 1.3459\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.5558 - loss: 1.6096\n",
            "Test accuracy: 0.5581938624382019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, the model reached about 96% accuracy on the training set, which shows it’s learning patterns well. However, the validation accuracy fluctuated and only reached 57%, with the validation loss sometimes increasing, suggesting overfitting. When we tested on unseen data, the accuracy was around 55.6%, close to random guessing. This means the model isn’t generalizing well. To improve, we could try adding dropout layers to reduce overfitting, using pre-trained embeddings for richer language understanding, or using early stopping to avoid over-training."
      ],
      "metadata": {
        "id": "9K5eqK53IGrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Identifying a Failure Case"
      ],
      "metadata": {
        "id": "faPydJpRJlv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, to understand the model's limitations, we examine a failure case where the prediction doesn’t match the true label."
      ],
      "metadata": {
        "id": "1rQylSkOKE_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test set\n",
        "predictions = model.predict(test_tokens['input_ids'])\n",
        "predicted_labels = tf.argmax(predictions, axis=1).numpy()\n",
        "\n",
        "# Finding a failure case\n",
        "for i in range(len(test_df)):\n",
        "    if predicted_labels[i] != test_df['label'].iloc[i]:\n",
        "        print(f\"Failure case at index {i}:\")\n",
        "        print(f\"Question: {test_df['qtext'].iloc[i]}\")\n",
        "        print(f\"Answer: {test_df['atext'].iloc[i]}\")\n",
        "        print(f\"True Label: {test_df['label'].iloc[i]}, Predicted: {predicted_labels[i]}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2-JGlfeKlBd",
        "outputId": "bd2403f2-5d8f-4535-c941-477d792343c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 72ms/step\n",
            "Failure case at index 0:\n",
            "Question: How does an external catheter help male incontinence?\n",
            "Answer: External catheters.\n",
            "True Label: 1, Predicted: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the question asks about how an external catheter helps with male incontinence, and the answer simply states \"External catheters.\" The true label is 1, meaning the answer is relevant, but the model predicted 0, which means it thought the answer was unrelated. This might be because the model didn’t fully understand the context and missed the relationship between \"external catheter\" in the question and \"external catheters\" in the answer. To improve, we could try using pre-trained embeddings to help the model capture more context, or add more similar examples in the training set to help it learn this kind of relationship."
      ],
      "metadata": {
        "id": "xh9TMDTULLc-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "a7b63e7410c98f344f02082f10d790581d1dba1eeb1c8fe30f342f6109f0429e"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3500a1362f294095933ac308dcc25dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62928734b47a496d97a8ac3d01915204",
              "IPY_MODEL_716bb9bda4d24a6f9f3400b7f8fc5bf1",
              "IPY_MODEL_077b196593854b07a82c663b84335c61"
            ],
            "layout": "IPY_MODEL_87efc2f4380449dca6b326b4dd2dfcaa"
          }
        },
        "62928734b47a496d97a8ac3d01915204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866eb63a8d8b4fd19ead508fb09a748b",
            "placeholder": "​",
            "style": "IPY_MODEL_1411ca0fb75948d68f190efed9c0e13d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "716bb9bda4d24a6f9f3400b7f8fc5bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf1060e137cf4714802941f38a0386ec",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f500a459f63c408bad8f9193b68b0a2d",
            "value": 48
          }
        },
        "077b196593854b07a82c663b84335c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_898a66e243cd4ca799c9625f84c08ab3",
            "placeholder": "​",
            "style": "IPY_MODEL_440b2446857c4113a74b35a77d30212a",
            "value": " 48.0/48.0 [00:00&lt;00:00, 668B/s]"
          }
        },
        "87efc2f4380449dca6b326b4dd2dfcaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866eb63a8d8b4fd19ead508fb09a748b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1411ca0fb75948d68f190efed9c0e13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf1060e137cf4714802941f38a0386ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f500a459f63c408bad8f9193b68b0a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "898a66e243cd4ca799c9625f84c08ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440b2446857c4113a74b35a77d30212a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9bb8e60c6484f1fae89b05b82fe790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f97d994a60d4834a1dde6dcd89dc85f",
              "IPY_MODEL_3bcd01518a174a1a9ac264a1007cad34",
              "IPY_MODEL_7f4ce309d19f4f91ad6963e343b97d0f"
            ],
            "layout": "IPY_MODEL_b1d6041d64f640fab876394d6ccf9d31"
          }
        },
        "0f97d994a60d4834a1dde6dcd89dc85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a0b9f0ce9a47309026056dec530d00",
            "placeholder": "​",
            "style": "IPY_MODEL_34bc1d4571cb494f98dac4fa6374b7d6",
            "value": "vocab.txt: 100%"
          }
        },
        "3bcd01518a174a1a9ac264a1007cad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1b6ed8fd654e20afb6cc89f5837d9c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9776f35b8534806a79932ea027d912a",
            "value": 231508
          }
        },
        "7f4ce309d19f4f91ad6963e343b97d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377e5f5435bc4d2f8292fba27d3f4843",
            "placeholder": "​",
            "style": "IPY_MODEL_bc2c61e7342e4966b4de5b1654955816",
            "value": " 232k/232k [00:00&lt;00:00, 2.53MB/s]"
          }
        },
        "b1d6041d64f640fab876394d6ccf9d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a0b9f0ce9a47309026056dec530d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34bc1d4571cb494f98dac4fa6374b7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce1b6ed8fd654e20afb6cc89f5837d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9776f35b8534806a79932ea027d912a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377e5f5435bc4d2f8292fba27d3f4843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2c61e7342e4966b4de5b1654955816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a14020105b57477c9c70c61b88546866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65af1e2a7d714e5b8361dd2cf81b1b3c",
              "IPY_MODEL_b5ced02830c94b5b8e9d67f041e7a473",
              "IPY_MODEL_3b2cf674c28040fd99fdf04150d5042b"
            ],
            "layout": "IPY_MODEL_4dbbe87fbdb14bc285afb14e13ac656b"
          }
        },
        "65af1e2a7d714e5b8361dd2cf81b1b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15527272405e42c3ad14f79b5e290d2a",
            "placeholder": "​",
            "style": "IPY_MODEL_60504385c3dc434c934f69229f39c3a8",
            "value": "tokenizer.json: 100%"
          }
        },
        "b5ced02830c94b5b8e9d67f041e7a473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e10f1b6c4b46dea081ed27ead1801b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6bdaa0897144ea795e58e290e97ea0d",
            "value": 466062
          }
        },
        "3b2cf674c28040fd99fdf04150d5042b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef827a3104164ed0a96e280383095506",
            "placeholder": "​",
            "style": "IPY_MODEL_629f3231c14245d9acd564e07014d88d",
            "value": " 466k/466k [00:00&lt;00:00, 2.19MB/s]"
          }
        },
        "4dbbe87fbdb14bc285afb14e13ac656b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15527272405e42c3ad14f79b5e290d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60504385c3dc434c934f69229f39c3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01e10f1b6c4b46dea081ed27ead1801b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bdaa0897144ea795e58e290e97ea0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef827a3104164ed0a96e280383095506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "629f3231c14245d9acd564e07014d88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b652d782f8ca41e3af2b977c33d8e366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81c2817e97574e26aa6bd08380ae6b06",
              "IPY_MODEL_4054cb166ee74662bd8313ca8172e57f",
              "IPY_MODEL_985edcdb80d84d35b1f1e03b010ad276"
            ],
            "layout": "IPY_MODEL_0ed6eebfcb4540059074c71f353361be"
          }
        },
        "81c2817e97574e26aa6bd08380ae6b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c3be6138834c72978afcee48f41df9",
            "placeholder": "​",
            "style": "IPY_MODEL_217d1abf2ca04cfa9d00724812ca5542",
            "value": "config.json: 100%"
          }
        },
        "4054cb166ee74662bd8313ca8172e57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048c748103d143029f52bea39f45a259",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb380a96e6554339b7da8ab95838d539",
            "value": 570
          }
        },
        "985edcdb80d84d35b1f1e03b010ad276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5107f42c19f48d392016c9094580af4",
            "placeholder": "​",
            "style": "IPY_MODEL_92e02f50739942548ca76e31b9d96ec5",
            "value": " 570/570 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "0ed6eebfcb4540059074c71f353361be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c3be6138834c72978afcee48f41df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217d1abf2ca04cfa9d00724812ca5542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "048c748103d143029f52bea39f45a259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb380a96e6554339b7da8ab95838d539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5107f42c19f48d392016c9094580af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e02f50739942548ca76e31b9d96ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}